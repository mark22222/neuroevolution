{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as funct\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from IPython import display\n",
    "import copy\n",
    "from itertools import count\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just to get rid of annoying warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=np.VisibleDeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    \"\"\"A Feed Forward Neural Network used for Deep-Q-Learning to solve the cartpole problem.\"\"\"\n",
    "    def __init__(self, obs_dim = env.observation_space.shape, n_actions = env.action_space.n):\n",
    "        super(NN, self).__init__()      \n",
    "        # The input (an observation/a state) has shape (4,) [cart pos, cart vel, pole angle, pole angular vel]\n",
    "        self.fc1 = nn.Linear(*obs_dim, 128) # * to convert tuple (4,) to 4\n",
    "        self.fc21 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, n_actions) # n_actions == 2\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=1e-4)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = funct.relu(self.fc1(x))\n",
    "        x = funct.relu(self.fc21(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    # represents the agent of the RL\n",
    "    def __init__(self, obs_dim = env.observation_space.shape, n_actions = env.action_space.n, \n",
    "                 eps = 0.05, popSize=20):\n",
    "        \n",
    "        self.obs_dim = obs_dim\n",
    "        self.n_actions = n_actions\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.eps = eps\n",
    "        self.popSize = popSize\n",
    "        self.population = [NN() for _ in range(self.popSize)]\n",
    "\n",
    "    def pick_action(self, state, nn):\n",
    "        if np.random.random() > self.eps:\n",
    "            actions = nn.forward(state) \n",
    "            action =  torch.argmax(actions).item()\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "        return action\n",
    "    \n",
    "    def train(self, max_iter):\n",
    "        iter = 0\n",
    "        fitness = [-1 for _ in range(self.popSize)]\n",
    "        while iter < max_iter and fitness[0] < 450:\n",
    "            children = self.reprod()\n",
    "            self.mutation(children)\n",
    "            self.population.extend(children)\n",
    "            fitness = self.fitness(reps=3)\n",
    "            self.selection(fitness)\n",
    "            print(iter)\n",
    "            iter += 1\n",
    "\n",
    "    def fitness(self, reps):\n",
    "        fitness = {}\n",
    "        idx = 0\n",
    "        for nn in self.population:\n",
    "            sum = 0\n",
    "            for _ in range(reps):\n",
    "                sum += self.play(nn)\n",
    "            fitness.update([(idx, sum/reps)])\n",
    "            idx += 1\n",
    "        return fitness\n",
    "    \n",
    "    def selection(self, fitness):\n",
    "        \"\"\"Elitist Selection\"\"\"\n",
    "        sortedFitness = sorted(fitness.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        idcs = [e[0] for e in sortedFitness[:self.popSize]]\n",
    "        self.population = [self.population[i] for i in idcs]\n",
    "\n",
    "    def mutation(self, children):\n",
    "        for nn in children:\n",
    "            nn.fc1.weight = torch.nn.Parameter(nn.fc1.weight.add(torch.Tensor(np.random.normal(size=np.shape(nn.fc1)))))\n",
    "            nn.fc21.weight = torch.nn.Parameter(nn.fc21.weight.add(torch.Tensor(np.random.normal(size=np.shape(nn.fc21)))))\n",
    "            nn.fc3.weight = torch.nn.Parameter(nn.fc3.weight.add(torch.Tensor(np.random.normal(size=np.shape(nn.fc3)))))\n",
    "\n",
    "    def reprod(self):\n",
    "        new = []\n",
    "        for nn in self.population:\n",
    "            new.append(copy.deepcopy(nn))\n",
    "        return new\n",
    "\n",
    "    def play(self, nn: NN):\n",
    "        obs, _ = env.reset()\n",
    "        obs = torch.tensor(obs, dtype=torch.float, device=nn.device)\n",
    "        score = 0\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        while not terminated and not truncated:\n",
    "            action = self.pick_action(obs, nn)\n",
    "            obs_, reward, terminated, truncated, _ = env.step(action)\n",
    "            obs = torch.tensor(obs_, dtype=torch.float, device=nn.device)\n",
    "            #display.clear_output(wait=True)\n",
    "            score += 1\n",
    "            #print(\"Score: \" + str(score))\n",
    "            #sleep(0.1)\n",
    "        #env.close\n",
    "        return score\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(reps=5, popSize=20, iter=500):\n",
    "    agent = Agent(popSize)\n",
    "    agent.train(iter)\n",
    "    sum = 0\n",
    "    for _ in range(reps):\n",
    "        sum += agent.play(agent.population[0])\n",
    "    print(sum/reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "73.8\n"
     ]
    }
   ],
   "source": [
    "execute(popSize=20, iter=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

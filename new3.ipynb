{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "\n",
    "    def __init__(self, hiddenLayer_neuron = 2,learning_rate = 0.1, batch_size = 2):\n",
    "\n",
    "        self.data = np.array([[0,0],\n",
    "                              [0,1],\n",
    "                              [1,0],\n",
    "                              [1,1]])\n",
    "        self.target = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "        self.hl_neuron = hiddenLayer_neuron\n",
    "\n",
    "        \n",
    "        self.w_hidden = np.random.uniform(size=(2,self.hl_neuron))\n",
    "        self.w_out = np.random.uniform(size=(self.hl_neuron,1))\n",
    "\n",
    "        self.b_hidden = np.random.uniform(size=(1,self.hl_neuron))\n",
    "        self.b_out = np.random.uniform(size=(1,1))\n",
    "\n",
    "        self.z0s = []\n",
    "        self.z1s = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        print(\"Init: \")\n",
    "        self.print_weights()\n",
    "\n",
    "    def ReLU(self,x):\n",
    "        return x * (x > 0) \n",
    "    \n",
    "    def bcel(self, y, y_hat):\n",
    "        return -(y*np.log(y_hat) + (1-y) * np.log(1-y_hat))\n",
    "    \n",
    "    def drv_loss_start(self, y, y_hat):\n",
    "        return 1 / (1-y_hat) if y == 0 else -1 / y_hat\n",
    "\n",
    "    def drv_loss(self, y, y_hat):\n",
    "        return y_hat-y\n",
    "    \n",
    "    def drv_sigmoid(self, z):\n",
    "        return self.sigmoid(z) * (1-self.sigmoid(z))\n",
    "    \n",
    "    '''def drv_sigmoid(self, sigmoid_value):\n",
    "        return sigmoid_value * (1-sigmoid_value)'''\n",
    "    \n",
    "    def drv_ReLU(self, z):\n",
    "        return 1 * (z > 0)\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def execute(self,x):\n",
    "        result = self.sigmoid(self.forward_pass(x)[0])\n",
    "        return np.round(result)\n",
    "    \n",
    "    def forward_pass(self,x):\n",
    "        x = np.array(x)\n",
    "        z0 = np.dot(x,self.w_hidden) + self.b_hidden\n",
    "        hidden = self.ReLU(z0)\n",
    "        z1 = np.dot(hidden,self.w_out) + self.b_out\n",
    "        return z1, z0\n",
    "    \n",
    "\n",
    "    def backward_pass(self,x,y,z1,z0):\n",
    "\n",
    "        x = np.array(x)\n",
    "\n",
    "        y_hat = self.sigmoid(z1)\n",
    "        \n",
    "        d1 = self.drv_loss(y,y_hat) / self.batch_size\n",
    "        d0 = self.drv_loss(y,y_hat) * np.dot(self.drv_ReLU(z0),self.w_out) / self.batch_size\n",
    "\n",
    "        self.w_out -= self.lr * np.dot(self.ReLU(z0).T,d1) \n",
    "        self.w_hidden -=  self.lr * np.dot(x.T,d0)\n",
    "\n",
    "        self.b_out -= self.lr * np.sum(d1, axis=0, keepdims=True)\n",
    "        self.b_hidden -= self.lr * np.sum(d0, axis=0, keepdims=True)\n",
    "        \n",
    "    def print_weights(self):\n",
    "        print(\"W_hidden: \" + str(self.w_hidden)) \n",
    "        print(\"B_hidden: \" + str(self.b_hidden)) \n",
    "        print(\"W_out: \" + str(self.w_out)) \n",
    "        print(\"B_out: \" + str(self.b_out), end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "    def accuracy(self):\n",
    "        counter = 0\n",
    "    \n",
    "        for i in range(len(self.data)):\n",
    "            if(self.execute(self.data[i]) == self.target[i]):\n",
    "                counter += 1\n",
    "        loss = 0\n",
    "        for i in range(len(self.data)):\n",
    "            loss += self.bcel(self.target[i],self.sigmoid(self.forward_pass(self.data[i])[0]))\n",
    "\n",
    "        return counter / len(self.data), loss / len(self.data)\n",
    "     \n",
    "    def train(self,epochs, fast_train = False):\n",
    "\n",
    "\n",
    "        if(epochs > 0):\n",
    "            for epoch in range(epochs):\n",
    "                print(\"Starting epoch: \" + str(epoch+1))\n",
    "                index = index = np.random.randint(4,size=self.batch_size)\n",
    "                batch = []\n",
    "                y = []\n",
    "                for i in index:\n",
    "                    batch.append(self.data[i])\n",
    "                    y.append(self.target[i])\n",
    "\n",
    "                z1,z0 = self.forward_pass(batch)\n",
    "                self.backward_pass(batch,y,z1,z0)\n",
    "\n",
    "                acc, loss =  self.accuracy()\n",
    "                print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                print(\"Current loss: \" +f\"{loss}\")\n",
    "        else:\n",
    "            epoch = 1\n",
    "            acc = 0\n",
    "            while acc != 1:\n",
    "                print(\"Starting epoch: \" + str(epoch))\n",
    "                index = index = np.random.randint(4,size=self.batch_size)\n",
    "                batch = []\n",
    "                y = []\n",
    "                for i in index:\n",
    "                    batch.append(self.data[i])\n",
    "                    y.append(self.target[i])\n",
    "\n",
    "                z1,z0 = self.forward_pass(batch)\n",
    "                self.backward_pass(batch,y,z1,z0)\n",
    "\n",
    "                acc, loss =  self.accuracy()\n",
    "                print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                print(\"Current loss: \" +f\"{loss}\")\n",
    "\n",
    "                epoch +=1 \n",
    "\n",
    "        \n",
    "        self.print_weights\n",
    "                \n",
    "        '''if epochs > 0:\n",
    "            for epoch in range(epochs):\n",
    "                index = np.random.randint(4,size=self.batch_size)\n",
    "                for i in index:\n",
    "                    z1, z0 = self.forward_pass(self.data[i])\n",
    "                    self.z0s.append(z0)\n",
    "                    self.z1s.append(z1)\n",
    "\n",
    "                self.z1s.reverse()\n",
    "                self.z0s.reverse()\n",
    "\n",
    "                if not fast_train:\n",
    "\n",
    "                    for i in tqdm(index,desc=\"Epoch: \" + str(epoch)): \n",
    "                        self.backward_pass(self.data[i],self.target[i])\n",
    "                        sleep(.1)\n",
    "                    acc, loss =  self.accuracy()\n",
    "                    print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                    print(\"Current loss: \" +f\"{loss}\")\n",
    "                \n",
    "                else:\n",
    "                    for i in index:\n",
    "                        self.backward_pass(self.data[i],self.target[i])\n",
    "                    acc, loss =  self.accuracy()\n",
    "            \n",
    "            print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "            print(\"Current loss: \" +f\"{loss}\")\n",
    "\n",
    "        \n",
    "        else:\n",
    "            epoch = 0\n",
    "            acc = 0\n",
    "            while acc  != 1:\n",
    "                index = np.random.randint(4,size=self.batch_size)\n",
    "                for i in index:\n",
    "                    z1, z0 = self.forward_pass(self.data[i])\n",
    "                    self.z0s.append(z0)\n",
    "                    self.z1s.append(z1)\n",
    "\n",
    "                self.z1s.reverse()\n",
    "                self.z0s.reverse()\n",
    "\n",
    "                if not fast_train:\n",
    "\n",
    "                    for i in tqdm(index,desc=\"Epoch: \" + str(epoch)): \n",
    "                        self.backward_pass(self.data[i],self.target[i])\n",
    "                        sleep(.1)\n",
    "                    acc, loss =  self.accuracy()\n",
    "                    print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                    print(\"Current loss: \" +f\"{loss}\")\n",
    "                \n",
    "                else:\n",
    "                    for i in index:\n",
    "                        self.backward_pass(self.data[i],self.target[i])\n",
    "                    acc, loss =  self.accuracy()\n",
    "                    print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                    print(\"Current loss: \" +f\"{loss}\")\n",
    "                    \n",
    "                epoch += 1\n",
    "        print(\"Epochs trained: \" + str(epoch+1))\n",
    "        self.print_weights()\n",
    "        print(acc)\n",
    "        return acc       '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: \n",
      "W_hidden: [[0.52665789 0.09348639 0.06644959 0.46357852 0.92379167 0.6757116\n",
      "  0.86593745 0.83249435]\n",
      " [0.71183557 0.99722739 0.76902738 0.3237747  0.11759066 0.30603526\n",
      "  0.24185284 0.28344915]]\n",
      "B_hidden: [[0.08695019 0.97409431 0.99023353 0.52824938 0.85903529 0.69129579\n",
      "  0.13538677 0.34027063]]\n",
      "W_out: [[0.30281776]\n",
      " [0.99435593]\n",
      " [0.95250856]\n",
      " [0.27453381]\n",
      " [0.89150473]\n",
      " [0.70585148]\n",
      " [0.23770862]\n",
      " [0.04090144]]\n",
      "B_out: [[0.64995528]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn = NN(8,learning_rate=0.1, batch_size= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 1\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[2.27756061]]\n",
      "Starting epoch: 2\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[1.64759333]]\n",
      "Starting epoch: 3\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[1.22617123]]\n",
      "Starting epoch: 4\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.94766591]]\n",
      "Starting epoch: 5\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.79085967]]\n",
      "Starting epoch: 6\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.6992188]]\n",
      "Starting epoch: 7\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.66562902]]\n",
      "Starting epoch: 8\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.65729931]]\n",
      "Starting epoch: 9\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.65118704]]\n",
      "Starting epoch: 10\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.64641034]]\n",
      "Starting epoch: 11\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.64435803]]\n",
      "Starting epoch: 12\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.64168321]]\n",
      "Starting epoch: 13\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.63996715]]\n",
      "Starting epoch: 14\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.63715979]]\n",
      "Starting epoch: 15\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.63589623]]\n",
      "Starting epoch: 16\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.63399006]]\n",
      "Starting epoch: 17\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.63243891]]\n",
      "Starting epoch: 18\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.63196721]]\n",
      "Starting epoch: 19\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.63047195]]\n",
      "Starting epoch: 20\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.62941601]]\n",
      "Starting epoch: 21\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.62784686]]\n",
      "Starting epoch: 22\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.6267676]]\n",
      "Starting epoch: 23\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.62575974]]\n",
      "Starting epoch: 24\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.62439328]]\n",
      "Starting epoch: 25\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.62292041]]\n",
      "Starting epoch: 26\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.62215689]]\n",
      "Starting epoch: 27\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.62146812]]\n",
      "Starting epoch: 28\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.62056237]]\n",
      "Starting epoch: 29\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61923717]]\n",
      "Starting epoch: 30\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61840741]]\n",
      "Starting epoch: 31\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61645166]]\n",
      "Starting epoch: 32\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61540779]]\n",
      "Starting epoch: 33\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61433913]]\n",
      "Starting epoch: 34\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61401725]]\n",
      "Starting epoch: 35\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61323875]]\n",
      "Starting epoch: 36\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61228934]]\n",
      "Starting epoch: 37\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61129457]]\n",
      "Starting epoch: 38\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.61058546]]\n",
      "Starting epoch: 39\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60932612]]\n",
      "Starting epoch: 40\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60820284]]\n",
      "Starting epoch: 41\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60724505]]\n",
      "Starting epoch: 42\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60681794]]\n",
      "Starting epoch: 43\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60541663]]\n",
      "Starting epoch: 44\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.6049686]]\n",
      "Starting epoch: 45\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60399934]]\n",
      "Starting epoch: 46\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60336635]]\n",
      "Starting epoch: 47\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60252593]]\n",
      "Starting epoch: 48\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60187692]]\n",
      "Starting epoch: 49\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60118983]]\n",
      "Starting epoch: 50\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.60062952]]\n",
      "Starting epoch: 51\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.59991638]]\n",
      "Starting epoch: 52\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.5992616]]\n",
      "Starting epoch: 53\n",
      "Current accuracy: 100.0%\n",
      "Current loss: [[0.59823247]]\n"
     ]
    }
   ],
   "source": [
    "nn.train(epochs = -1,fast_train=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(nn.execute([0,0]))\n",
    "print(nn.execute([0,1]))\n",
    "print(nn.execute([1,0]))\n",
    "print(nn.execute([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "\n",
    "    def __init__(self, hiddenLayer_neuron = 2,learning_rate = 0.1):\n",
    "\n",
    "        self.data = np.array([[0,0],\n",
    "                              [0,1],\n",
    "                              [1,0],\n",
    "                              [1,1]])\n",
    "        self.target = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "        self.hl_neuron = hiddenLayer_neuron\n",
    "        \n",
    "        self.w_hidden = np.random.uniform(size=(2,self.hl_neuron))\n",
    "        self.w_out = np.random.uniform(size=(self.hl_neuron,1))\n",
    "\n",
    "        self.b_hidden = np.random.uniform(size=(1,self.hl_neuron))\n",
    "        self.b_out = np.random.uniform(size=(1,1))\n",
    "\n",
    "        self.z0s = []\n",
    "        self.z1s = []\n",
    "\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        print(\"Init: \")\n",
    "        self.print_weights()\n",
    "\n",
    "    def ReLU(self,x):\n",
    "        return x * (x > 0) \n",
    "    \n",
    "    def bcel(self, y, y_hat):\n",
    "        return -(y*np.log(y_hat) + (1-y) * np.log(1-y_hat))\n",
    "    \n",
    "    def drv_loss_start(self, y, y_hat):\n",
    "        return 1 / (1-y_hat) if y == 0 else -1 / y_hat\n",
    "\n",
    "    def drv_loss(self, y, y_hat):\n",
    "        return y_hat-y\n",
    "    \n",
    "    def drv_sigmoid(self, z):\n",
    "        return self.sigmoid(z) * (1-self.sigmoid(z))\n",
    "    \n",
    "    '''def drv_sigmoid(self, sigmoid_value):\n",
    "        return sigmoid_value * (1-sigmoid_value)'''\n",
    "    \n",
    "    def drv_ReLU(self, z):\n",
    "        return 1 * (z > 0)\n",
    "\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    def execute(self,x):\n",
    "        result = self.sigmoid(self.forward_pass(x)[0])\n",
    "        return np.round(result)\n",
    "    \n",
    "    def forward_pass(self,x):\n",
    "        x = np.array(x)\n",
    "        z0 = np.dot(x.T,self.w_hidden) + self.b_hidden\n",
    "        print(z0)\n",
    "        hidden = self.ReLU(z0)\n",
    "        z1 = np.dot(hidden,self.w_out) + self.b_out\n",
    "        return z1, z0\n",
    "    \n",
    "\n",
    "    def backward_pass(self,x,y):\n",
    "\n",
    "        alpha = 0.1\n",
    "        z1, z0 = self.z1s.pop(), self.z0s.pop()\n",
    "\n",
    "        y_hat = self.sigmoid(z1)\n",
    "        d1 = self.drv_loss_start(y,y_hat)*self.drv_sigmoid(z1)\n",
    "        d0 = self.drv_loss(y,y_hat) * np.dot(self.drv_ReLU(z0),self.w_out)\n",
    "\n",
    "        self.w_out -= alpha* np.dot(self.ReLU(z0).T,d1) \n",
    "        self.w_hidden -= alpha* np.dot(x.reshape(2,1),d0)\n",
    "\n",
    "        self.b_out -= alpha*np.sum(d1, axis=0, keepdims=True)\n",
    "        self.b_hidden -= alpha*np.sum(d0, axis=0, keepdims=True)\n",
    "        \n",
    "    def print_weights(self):\n",
    "        print(\"W_hidden: \" + str(self.w_hidden)) \n",
    "        print(\"B_hidden: \" + str(self.b_hidden)) \n",
    "        print(\"W_out: \" + str(self.w_out)) \n",
    "        print(\"B_out: \" + str(self.b_out), end=\"\\n\\n\")\n",
    "\n",
    "\n",
    "    def accuracy(self):\n",
    "        counter = 0\n",
    "    \n",
    "        for i in range(len(self.data)):\n",
    "            if(self.execute(self.data[i]) == self.target[i]):\n",
    "                counter += 1\n",
    "        loss = 0\n",
    "        for i in range(len(self.data)):\n",
    "            loss += self.bcel(self.target[i],self.sigmoid(self.forward_pass(self.data[i])[0]))\n",
    "\n",
    "        return counter / len(self.data), loss / len(self.data)\n",
    "     \n",
    "    def train(self,epochs, batch_size, fast_train = False):\n",
    "\n",
    "        if epochs > 0:\n",
    "            for epoch in range(epochs):\n",
    "                index = np.random.randint(4,size=batch_size)\n",
    "                for i in index:\n",
    "                    z1, z0 = self.forward_pass(self.data[i])\n",
    "                    self.z0s.append(z0)\n",
    "                    self.z1s.append(z1)\n",
    "\n",
    "                self.z1s.reverse()\n",
    "                self.z0s.reverse()\n",
    "\n",
    "                if not fast_train:\n",
    "\n",
    "                    for i in tqdm(index,desc=\"Epoch: \" + str(epoch)): \n",
    "                        self.backward_pass(self.data[i],self.target[i])\n",
    "                        sleep(.1)\n",
    "                    acc, loss =  self.accuracy()\n",
    "                    print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                    print(\"Current loss: \" +f\"{loss}\")\n",
    "                \n",
    "                else:\n",
    "                    for i in index:\n",
    "                        self.backward_pass(self.data[i],self.target[i])\n",
    "                    acc, loss =  self.accuracy()\n",
    "            \n",
    "            print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "            print(\"Current loss: \" +f\"{loss}\")\n",
    "\n",
    "        \n",
    "        else:\n",
    "            epoch = 0\n",
    "            acc = 0\n",
    "            while acc  != 1:\n",
    "                index = np.random.randint(4,size=batch_size)\n",
    "                for i in index:\n",
    "                    z1, z0 = self.forward_pass(self.data[i])\n",
    "                    self.z0s.append(z0)\n",
    "                    self.z1s.append(z1)\n",
    "\n",
    "                self.z1s.reverse()\n",
    "                self.z0s.reverse()\n",
    "\n",
    "                if not fast_train:\n",
    "\n",
    "                    for i in tqdm(index,desc=\"Epoch: \" + str(epoch)): \n",
    "                        self.backward_pass(self.data[i],self.target[i])\n",
    "                        sleep(.1)\n",
    "                    acc, loss =  self.accuracy()\n",
    "                    print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                    print(\"Current loss: \" +f\"{loss}\")\n",
    "                \n",
    "                else:\n",
    "                    for i in index:\n",
    "                        self.backward_pass(self.data[i],self.target[i])\n",
    "                    acc, loss =  self.accuracy()\n",
    "                    print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                    print(\"Current loss: \" +f\"{loss}\")\n",
    "                epoch += 1\n",
    "        print(\"Epochs trained: \" + str(epoch))\n",
    "        self.print_weights()\n",
    "\n",
    "        return acc\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: \n",
      "W_hidden: [[0.49117521 0.73442995 0.90891559 0.4789106 ]\n",
      " [0.96325737 0.60019308 0.9278356  0.61920373]]\n",
      "B_hidden: [[0.36671979 0.53911948 0.82064756 0.99800239]]\n",
      "W_out: [[0.96053171]\n",
      " [0.8293725 ]\n",
      " [0.80455441]\n",
      " [0.09888151]]\n",
      "B_out: [[0.5881767]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn = NN(4,learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.857895   1.27354943 1.72956314 1.476913  ]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (4,1) and (4,1) not aligned: 1 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[487], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nn\u001b[39m.\u001b[39;49mtrain(epochs \u001b[39m=\u001b[39;49m \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,fast_train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[485], line 135\u001b[0m, in \u001b[0;36mNN.train\u001b[1;34m(self, epochs, batch_size, fast_train)\u001b[0m\n\u001b[0;32m    133\u001b[0m index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(\u001b[39m4\u001b[39m,size\u001b[39m=\u001b[39mbatch_size)\n\u001b[0;32m    134\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m index:\n\u001b[1;32m--> 135\u001b[0m     z1, z0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_pass(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata[i])\n\u001b[0;32m    136\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz0s\u001b[39m.\u001b[39mappend(z0)\n\u001b[0;32m    137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mz1s\u001b[39m.\u001b[39mappend(z1)\n",
      "Cell \u001b[1;32mIn[485], line 60\u001b[0m, in \u001b[0;36mNN.forward_pass\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mprint\u001b[39m(z0)\n\u001b[0;32m     59\u001b[0m hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mReLU(z0)\n\u001b[1;32m---> 60\u001b[0m z1 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(hidden\u001b[39m.\u001b[39;49mT,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mw_out) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb_out\n\u001b[0;32m     61\u001b[0m \u001b[39mreturn\u001b[39;00m z1, z0\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (4,1) and (4,1) not aligned: 1 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "nn.train(epochs = -1,batch_size= 2,fast_train=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.17258183  0.53061269  0.01723316  0.13108194]]\n",
      "[[0.]]\n",
      "[[1.47944582 2.16063468 1.94008166 1.84856069]]\n",
      "[[1.]]\n",
      "[[-1.75212782 -1.09379707 -1.85328838 -1.08833044]]\n",
      "[[1.]]\n",
      "[[-0.10010017  0.53622492  0.06956012  0.62914832]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(nn.execute([0,0]))\n",
    "print(nn.execute([0,1]))\n",
    "print(nn.execute([1,0]))\n",
    "print(nn.execute([1,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

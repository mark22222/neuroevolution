{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN():\n",
    "\n",
    "    #creates a 3 layer NN with 2 input neuron, n hidden neuron and 1 ouput neuron\n",
    "    def __init__(self, hiddenLayer_neuron = 2,learning_rate = 0.1, batch_size = 2):\n",
    "\n",
    "        self.data = np.array([[0,0],\n",
    "                              [0,1],\n",
    "                              [1,0],\n",
    "                              [1,1]])\n",
    "        self.target = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "        self.hl_neuron = hiddenLayer_neuron\n",
    "\n",
    "        \n",
    "        self.w_hidden = np.random.uniform(size=(2,self.hl_neuron))\n",
    "        self.w_out = np.random.uniform(size=(self.hl_neuron,1))\n",
    "\n",
    "        self.b_hidden = np.random.uniform(size=(1,self.hl_neuron))\n",
    "        self.b_out = np.random.uniform(size=(1,1))\n",
    "\n",
    "        self.z0s = []\n",
    "        self.z1s = []\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        print(\"Init: \")\n",
    "        self.print_weights()\n",
    "\n",
    "    #ReLU function\n",
    "    def ReLU(self,x):\n",
    "        return x * (x > 0) \n",
    "    \n",
    "    #binary cross entropy loss function\n",
    "    def bcel(self, y, y_hat):\n",
    "        return -(y*np.log(y_hat) + (1-y) * np.log(1-y_hat))\n",
    "    \n",
    "    def drv_loss_start(self, y, y_hat):\n",
    "        return 1 / (1-y_hat) if y == 0 else -1 / y_hat\n",
    "\n",
    "    def drv_loss(self, y, y_hat):\n",
    "        return y_hat-y\n",
    "    \n",
    "    #sigmoid' function\n",
    "    def drv_sigmoid(self, z):\n",
    "        return self.sigmoid(z) * (1-self.sigmoid(z))\n",
    "    \n",
    "    #ReLU' function\n",
    "    def drv_ReLU(self, z):\n",
    "        return 1 * (z > 0)\n",
    "\n",
    "    #sigmoid function\n",
    "    def sigmoid(self,x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "    \n",
    "    #Execute the NN with input x\n",
    "    def execute(self,x):\n",
    "        result = self.sigmoid(self.forward_pass(x)[0])\n",
    "        return np.round(result)\n",
    "    \n",
    "    #forward pass\n",
    "    def forward_pass(self,x):\n",
    "        x = np.array(x)\n",
    "        z0 = np.dot(x,self.w_hidden) + self.b_hidden\n",
    "        hidden = self.ReLU(z0)\n",
    "        z1 = np.dot(hidden,self.w_out) + self.b_out\n",
    "        return z1, z0\n",
    "    \n",
    "    #backward pass\n",
    "    def backward_pass(self,x,y,z1,z0):\n",
    "\n",
    "        x = np.array(x)\n",
    "\n",
    "        y_hat = self.sigmoid(z1)\n",
    "        \n",
    "        d1 = self.drv_loss(y,y_hat) / self.batch_size\n",
    "        d0 = self.drv_loss(y,y_hat) * np.dot(self.drv_ReLU(z0),self.w_out) / self.batch_size\n",
    "\n",
    "        self.w_out -= self.lr * np.dot(self.ReLU(z0).T,d1) \n",
    "        self.w_hidden -=  self.lr * np.dot(x.T,d0)\n",
    "\n",
    "        self.b_out -= self.lr * np.sum(d1, axis=0, keepdims=True)\n",
    "        self.b_hidden -= self.lr * np.sum(d0, axis=0, keepdims=True)\n",
    "\n",
    "    #prints the weights of the nn  \n",
    "    def print_weights(self):\n",
    "        print(\"W_hidden: \" + str(self.w_hidden)) \n",
    "        print(\"B_hidden: \" + str(self.b_hidden)) \n",
    "        print(\"W_out: \" + str(self.w_out)) \n",
    "        print(\"B_out: \" + str(self.b_out), end=\"\\n\\n\")\n",
    "\n",
    "    #calculates the accuracy and current loss of the nn\n",
    "    def accuracy(self):\n",
    "        counter = 0\n",
    "    \n",
    "        for i in range(len(self.data)):\n",
    "            if(self.execute(self.data[i]) == self.target[i]):\n",
    "                counter += 1\n",
    "        loss = 0\n",
    "        for i in range(len(self.data)):\n",
    "            loss += self.bcel(self.target[i],self.sigmoid(self.forward_pass(self.data[i])[0]))\n",
    "\n",
    "        return counter / len(self.data), loss / len(self.data)\n",
    "     \n",
    "    #trains the nn\n",
    "    def train(self,epochs):\n",
    "\n",
    "        if(epochs > 0):\n",
    "            for epoch in range(epochs):\n",
    "                print(\"Starting epoch: \" + str(epoch+1))\n",
    "                index = index = np.random.randint(4,size=self.batch_size)\n",
    "                batch = []\n",
    "                y = []\n",
    "                for i in index:\n",
    "                    batch.append(self.data[i])\n",
    "                    y.append(self.target[i])\n",
    "\n",
    "                z1,z0 = self.forward_pass(batch)\n",
    "                self.backward_pass(batch,y,z1,z0)\n",
    "\n",
    "                acc, loss =  self.accuracy()\n",
    "                print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                print(\"Current loss: \" +f\"{loss}\")\n",
    "        else:\n",
    "            epoch = 1\n",
    "            acc = 0\n",
    "            while acc != 1:\n",
    "                print(\"Starting epoch: \" + str(epoch))\n",
    "                index = index = np.random.randint(4,size=self.batch_size)\n",
    "                batch = []\n",
    "                y = []\n",
    "                for i in index:\n",
    "                    batch.append(self.data[i])\n",
    "                    y.append(self.target[i])\n",
    "\n",
    "                z1,z0 = self.forward_pass(batch)\n",
    "                self.backward_pass(batch,y,z1,z0)\n",
    "\n",
    "                acc, loss =  self.accuracy()\n",
    "                print(\"Current accuracy: \" +f\"{acc*100}%\")\n",
    "                print(\"Current loss: \" +f\"{loss}\")\n",
    "\n",
    "                epoch +=1 \n",
    "\n",
    "        \n",
    "        self.print_weights\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: \n",
      "W_hidden: [[0.54201588 0.88427632 0.10429327 0.9618789  0.5967144  0.01767469\n",
      "  0.72491459 0.77801837]\n",
      " [0.66817707 0.85198823 0.26379981 0.78842197 0.45423032 0.12186967\n",
      "  0.35263309 0.5927359 ]]\n",
      "B_hidden: [[0.87690719 0.56341824 0.28729717 0.58535628 0.75616464 0.00222686\n",
      "  0.28089913 0.25186067]]\n",
      "W_out: [[0.08501164]\n",
      " [0.33980993]\n",
      " [0.26118278]\n",
      " [0.7156144 ]\n",
      " [0.5245008 ]\n",
      " [0.48494489]\n",
      " [0.12372622]\n",
      " [0.19182351]]\n",
      "B_out: [[0.13431766]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn = NN(8,learning_rate=0.1, batch_size= 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 1\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[1.2074365]]\n",
      "Starting epoch: 2\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[1.01213558]]\n",
      "Starting epoch: 3\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.90075682]]\n",
      "Starting epoch: 4\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.82682248]]\n",
      "Starting epoch: 5\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.7979389]]\n",
      "Starting epoch: 6\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.76539458]]\n",
      "Starting epoch: 7\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.74627107]]\n",
      "Starting epoch: 8\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.72875834]]\n",
      "Starting epoch: 9\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.71934804]]\n",
      "Starting epoch: 10\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.71294288]]\n",
      "Starting epoch: 11\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.70857765]]\n",
      "Starting epoch: 12\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.70781131]]\n",
      "Starting epoch: 13\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.70374261]]\n",
      "Starting epoch: 14\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.70089239]]\n",
      "Starting epoch: 15\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69855942]]\n",
      "Starting epoch: 16\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.6980347]]\n",
      "Starting epoch: 17\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69635947]]\n",
      "Starting epoch: 18\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69592967]]\n",
      "Starting epoch: 19\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69514449]]\n",
      "Starting epoch: 20\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69450348]]\n",
      "Starting epoch: 21\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69402844]]\n",
      "Starting epoch: 22\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69407556]]\n",
      "Starting epoch: 23\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69364184]]\n",
      "Starting epoch: 24\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.69302717]]\n",
      "Starting epoch: 25\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69269867]]\n",
      "Starting epoch: 26\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69220895]]\n",
      "Starting epoch: 27\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69214786]]\n",
      "Starting epoch: 28\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69173834]]\n",
      "Starting epoch: 29\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69157625]]\n",
      "Starting epoch: 30\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69138262]]\n",
      "Starting epoch: 31\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69119926]]\n",
      "Starting epoch: 32\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69108904]]\n",
      "Starting epoch: 33\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69090319]]\n",
      "Starting epoch: 34\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.69080119]]\n",
      "Starting epoch: 35\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.69066318]]\n",
      "Starting epoch: 36\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69051664]]\n",
      "Starting epoch: 37\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69037491]]\n",
      "Starting epoch: 38\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.69023428]]\n",
      "Starting epoch: 39\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.69008723]]\n",
      "Starting epoch: 40\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68990059]]\n",
      "Starting epoch: 41\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68978115]]\n",
      "Starting epoch: 42\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68955367]]\n",
      "Starting epoch: 43\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.6894553]]\n",
      "Starting epoch: 44\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68941241]]\n",
      "Starting epoch: 45\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68922788]]\n",
      "Starting epoch: 46\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.6889115]]\n",
      "Starting epoch: 47\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.6892181]]\n",
      "Starting epoch: 48\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68879065]]\n",
      "Starting epoch: 49\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68867992]]\n",
      "Starting epoch: 50\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68857585]]\n",
      "Starting epoch: 51\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68846569]]\n",
      "Starting epoch: 52\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.6883529]]\n",
      "Starting epoch: 53\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68859715]]\n",
      "Starting epoch: 54\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.6884122]]\n",
      "Starting epoch: 55\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68807712]]\n",
      "Starting epoch: 56\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68814028]]\n",
      "Starting epoch: 57\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68778971]]\n",
      "Starting epoch: 58\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68777679]]\n",
      "Starting epoch: 59\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68761466]]\n",
      "Starting epoch: 60\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68761781]]\n",
      "Starting epoch: 61\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68741796]]\n",
      "Starting epoch: 62\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68737411]]\n",
      "Starting epoch: 63\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68720323]]\n",
      "Starting epoch: 64\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.687133]]\n",
      "Starting epoch: 65\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68697279]]\n",
      "Starting epoch: 66\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68682648]]\n",
      "Starting epoch: 67\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68670303]]\n",
      "Starting epoch: 68\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68662993]]\n",
      "Starting epoch: 69\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68646694]]\n",
      "Starting epoch: 70\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68638243]]\n",
      "Starting epoch: 71\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68637176]]\n",
      "Starting epoch: 72\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68621694]]\n",
      "Starting epoch: 73\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.6861771]]\n",
      "Starting epoch: 74\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68602101]]\n",
      "Starting epoch: 75\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68607458]]\n",
      "Starting epoch: 76\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68594618]]\n",
      "Starting epoch: 77\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68563366]]\n",
      "Starting epoch: 78\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68564877]]\n",
      "Starting epoch: 79\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68548214]]\n",
      "Starting epoch: 80\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68558358]]\n",
      "Starting epoch: 81\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68513831]]\n",
      "Starting epoch: 82\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68563546]]\n",
      "Starting epoch: 83\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68494102]]\n",
      "Starting epoch: 84\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68488224]]\n",
      "Starting epoch: 85\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68445734]]\n",
      "Starting epoch: 86\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68428391]]\n",
      "Starting epoch: 87\n",
      "Current accuracy: 25.0%\n",
      "Current loss: [[0.68412632]]\n",
      "Starting epoch: 88\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68414162]]\n",
      "Starting epoch: 89\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68395933]]\n",
      "Starting epoch: 90\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68371557]]\n",
      "Starting epoch: 91\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68382377]]\n",
      "Starting epoch: 92\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68322428]]\n",
      "Starting epoch: 93\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68333406]]\n",
      "Starting epoch: 94\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68290185]]\n",
      "Starting epoch: 95\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68280329]]\n",
      "Starting epoch: 96\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68264355]]\n",
      "Starting epoch: 97\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68263003]]\n",
      "Starting epoch: 98\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68262086]]\n",
      "Starting epoch: 99\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.6821166]]\n",
      "Starting epoch: 100\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68196781]]\n",
      "Starting epoch: 101\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68181879]]\n",
      "Starting epoch: 102\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.68150867]]\n",
      "Starting epoch: 103\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68147082]]\n",
      "Starting epoch: 104\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68121604]]\n",
      "Starting epoch: 105\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.6810912]]\n",
      "Starting epoch: 106\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68084521]]\n",
      "Starting epoch: 107\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68090756]]\n",
      "Starting epoch: 108\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68050731]]\n",
      "Starting epoch: 109\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68048526]]\n",
      "Starting epoch: 110\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68006357]]\n",
      "Starting epoch: 111\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68016308]]\n",
      "Starting epoch: 112\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68055487]]\n",
      "Starting epoch: 113\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67982439]]\n",
      "Starting epoch: 114\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67954978]]\n",
      "Starting epoch: 115\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.68015793]]\n",
      "Starting epoch: 116\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67919537]]\n",
      "Starting epoch: 117\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67882365]]\n",
      "Starting epoch: 118\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67851865]]\n",
      "Starting epoch: 119\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67853688]]\n",
      "Starting epoch: 120\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.678508]]\n",
      "Starting epoch: 121\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67792702]]\n",
      "Starting epoch: 122\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67770659]]\n",
      "Starting epoch: 123\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67811851]]\n",
      "Starting epoch: 124\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.6778339]]\n",
      "Starting epoch: 125\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67821316]]\n",
      "Starting epoch: 126\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67709792]]\n",
      "Starting epoch: 127\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67733311]]\n",
      "Starting epoch: 128\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67644285]]\n",
      "Starting epoch: 129\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67553469]]\n",
      "Starting epoch: 130\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67520693]]\n",
      "Starting epoch: 131\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67458831]]\n",
      "Starting epoch: 132\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67478158]]\n",
      "Starting epoch: 133\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67478382]]\n",
      "Starting epoch: 134\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67415522]]\n",
      "Starting epoch: 135\n",
      "Current accuracy: 50.0%\n",
      "Current loss: [[0.67364896]]\n",
      "Starting epoch: 136\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67313725]]\n",
      "Starting epoch: 137\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67334746]]\n",
      "Starting epoch: 138\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67249937]]\n",
      "Starting epoch: 139\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67242585]]\n",
      "Starting epoch: 140\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67186075]]\n",
      "Starting epoch: 141\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67132293]]\n",
      "Starting epoch: 142\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67136704]]\n",
      "Starting epoch: 143\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67077131]]\n",
      "Starting epoch: 144\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67064941]]\n",
      "Starting epoch: 145\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.67014232]]\n",
      "Starting epoch: 146\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66968491]]\n",
      "Starting epoch: 147\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66936304]]\n",
      "Starting epoch: 148\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66897407]]\n",
      "Starting epoch: 149\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66861799]]\n",
      "Starting epoch: 150\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66816141]]\n",
      "Starting epoch: 151\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66775076]]\n",
      "Starting epoch: 152\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66740304]]\n",
      "Starting epoch: 153\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66692853]]\n",
      "Starting epoch: 154\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66650453]]\n",
      "Starting epoch: 155\n",
      "Current accuracy: 75.0%\n",
      "Current loss: [[0.66605137]]\n",
      "Starting epoch: 156\n",
      "Current accuracy: 100.0%\n",
      "Current loss: [[0.6655517]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.train(epochs = -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "[[1.]]\n",
      "[[1.]]\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(nn.execute([0,0]))\n",
    "print(nn.execute([0,1]))\n",
    "print(nn.execute([1,0]))\n",
    "print(nn.execute([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
